{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze FMCIB features for original and READII negative control CT images\n",
    "\n",
    "This notebook is set up to use outputs from the `run_fmcib.ipynb` notebook.\n",
    "\n",
    "Image features extracted from CT images cropped to a Gross Tumour Volume (GTV) undergo correlation analysis. Results are compared across READII negative control image types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up pixi environment kernel\n",
    "\n",
    "1. Run the following commands in the terminal:\n",
    "\n",
    "    ```bash\n",
    "    $ pixi install\n",
    "\n",
    "    $ pixi run make_kernel\n",
    "    ```\n",
    "\n",
    "2. In the `Select Kernel` menu at the top right of the notebook, select `Jupyter Kernel` as the source. \n",
    "\n",
    "3. Refresh the options and one called `readii-fmcib` should appear. Select this option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from readii.io.loaders import loadImageDatasetConfig, loadFeatureFilesFromImageTypes\n",
    "from readii.io.writers.correlation_writer import CorrelationWriter\n",
    "from readii.analyze.correlation import getFeatureCorrelations \n",
    "\n",
    "\n",
    "import sys; sys.path.append(\"code\")\n",
    "from analyze import prepPatientIndex, makeAllHeatmapPlots, makeAllHistogramPlots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize dataset name and load config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = loadImageDatasetConfig(\"RADCURE\", Path(\"config\"))\n",
    "\n",
    "DATASET_NAME = config[\"dataset_name\"]\n",
    "\n",
    "PAT_ID_PATTERN = config['patient_id_pattern']\n",
    "\n",
    "NEG_CONTROL_REGIONS = config[\"negative_control_regions\"]\n",
    "NEG_CONTROL_TYPES = config[\"negative_control_types\"]\n",
    "\n",
    "CROP_METHOD = config['crop_method']\n",
    "\n",
    "# Get full list of image types to run FMCIB on\n",
    "negative_control_list = [f\"{negative_control[0]}_{negative_control[1]}\" for negative_control in itertools.product(NEG_CONTROL_TYPES, NEG_CONTROL_REGIONS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features input directory\n",
    "features_dir = Path(\"results\", DATASET_NAME, \"fmcib_features\", f\"cropped_{CROP_METHOD}\")\n",
    "\n",
    "# Make correlation results output directory\n",
    "correlations_dir = Path(\"results\", DATASET_NAME, \"analysis\", \"correlations\", f\"cropped_{CROP_METHOD}\")\n",
    "for combo in itertools.product([correlations_dir], [\"matrix\", \"heatmap\", \"histogram\"]):\n",
    "    Path(*combo).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all extracted feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the extracted feature data\n",
    "# This makes a dictionary of feature sets, with the image type as the keys\n",
    "extracted_feature_sets = loadFeatureFilesFromImageTypes(extracted_feature_dir=features_dir,\n",
    "                                                        image_types = ([\"original\"] + negative_control_list), \n",
    "                                                        drop_labels = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run correlation analysis for each image type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up writers for correlation and plots\n",
    "corr_matrix_writer = CorrelationWriter(\n",
    "    root_directory = correlations_dir / \"matrix\",\n",
    "    filename_format = DATASET_NAME + \"_{VerticalFeatureType}_{HorizontalFeatureType}_{CorrelationType}_correlations.csv\",\n",
    "    overwrite = False,\n",
    "    create_dirs = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing original vs shuffled_full correlations.\n",
      "     Calculating correlation matrix.\n",
      "     Generating heatmaps for correlations.\n",
      "Plotting vertical feature correlations heatmap...\n",
      "Plotting horizontal feature correlations heatmap...\n",
      "Plotting cross feature correlations heatmap...\n",
      "     Generating histograms for correlations.\n",
      "Plotting vertical feature correlations histogram...\n",
      "Plotting horizontal feature correlations histogram...\n",
      "Plotting cross feature correlations histogram...\n",
      "Processing original vs shuffled_roi correlations.\n",
      "     Calculating correlation matrix.\n",
      "     Generating heatmaps for correlations.\n",
      "Plotting vertical feature correlations heatmap...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-01-10T16:31:01-0500\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mFile results/RADCURE/analysis/correlations/cropped_cube/heatmap/nipy_spectral/original_pearson_self_correlation_heatmap.png already exists. Overwriting.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mreadii\u001b[0m]\u001b[0m \u001b[36mcall\u001b[0m=\u001b[35mplot_writer.save:92\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting horizontal feature correlations heatmap...\n",
      "Plotting cross feature correlations heatmap...\n",
      "     Generating histograms for correlations.\n",
      "Plotting vertical feature correlations histogram...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-01-10T16:31:34-0500\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mFile results/RADCURE/analysis/correlations/cropped_cube/histogram/original_pearson_self_correlation_histogram.png already exists. Overwriting.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mreadii\u001b[0m]\u001b[0m \u001b[36mcall\u001b[0m=\u001b[35mplot_writer.save:92\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting horizontal feature correlations histogram...\n",
      "Plotting cross feature correlations histogram...\n",
      "Processing original vs shuffled_non_roi correlations.\n",
      "     Calculating correlation matrix.\n",
      "     Generating heatmaps for correlations.\n",
      "Plotting vertical feature correlations heatmap...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-01-10T16:34:30-0500\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mFile results/RADCURE/analysis/correlations/cropped_cube/heatmap/nipy_spectral/original_pearson_self_correlation_heatmap.png already exists. Overwriting.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mreadii\u001b[0m]\u001b[0m \u001b[36mcall\u001b[0m=\u001b[35mplot_writer.save:92\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting horizontal feature correlations heatmap...\n",
      "Plotting cross feature correlations heatmap...\n",
      "     Generating histograms for correlations.\n",
      "Plotting vertical feature correlations histogram...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-01-10T16:35:03-0500\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mFile results/RADCURE/analysis/correlations/cropped_cube/histogram/original_pearson_self_correlation_histogram.png already exists. Overwriting.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mreadii\u001b[0m]\u001b[0m \u001b[36mcall\u001b[0m=\u001b[35mplot_writer.save:92\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting horizontal feature correlations histogram...\n",
      "Plotting cross feature correlations histogram...\n",
      "Processing original vs randomized_sampled_full correlations.\n",
      "     Calculating correlation matrix.\n",
      "     Generating heatmaps for correlations.\n",
      "Plotting vertical feature correlations heatmap...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-01-10T16:37:59-0500\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mFile results/RADCURE/analysis/correlations/cropped_cube/heatmap/nipy_spectral/original_pearson_self_correlation_heatmap.png already exists. Overwriting.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mreadii\u001b[0m]\u001b[0m \u001b[36mcall\u001b[0m=\u001b[35mplot_writer.save:92\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting horizontal feature correlations heatmap...\n",
      "Plotting cross feature correlations heatmap...\n",
      "     Generating histograms for correlations.\n",
      "Plotting vertical feature correlations histogram...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-01-10T16:38:32-0500\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mFile results/RADCURE/analysis/correlations/cropped_cube/histogram/original_pearson_self_correlation_histogram.png already exists. Overwriting.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mreadii\u001b[0m]\u001b[0m \u001b[36mcall\u001b[0m=\u001b[35mplot_writer.save:92\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting horizontal feature correlations histogram...\n",
      "Plotting cross feature correlations histogram...\n",
      "Processing original vs randomized_sampled_roi correlations.\n",
      "     Calculating correlation matrix.\n",
      "     Generating heatmaps for correlations.\n",
      "Plotting vertical feature correlations heatmap...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-01-10T16:41:26-0500\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mFile results/RADCURE/analysis/correlations/cropped_cube/heatmap/nipy_spectral/original_pearson_self_correlation_heatmap.png already exists. Overwriting.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mreadii\u001b[0m]\u001b[0m \u001b[36mcall\u001b[0m=\u001b[35mplot_writer.save:92\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting horizontal feature correlations heatmap...\n",
      "Plotting cross feature correlations heatmap...\n",
      "     Generating histograms for correlations.\n",
      "Plotting vertical feature correlations histogram...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-01-10T16:41:59-0500\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mFile results/RADCURE/analysis/correlations/cropped_cube/histogram/original_pearson_self_correlation_histogram.png already exists. Overwriting.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mreadii\u001b[0m]\u001b[0m \u001b[36mcall\u001b[0m=\u001b[35mplot_writer.save:92\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting horizontal feature correlations histogram...\n",
      "Plotting cross feature correlations histogram...\n",
      "Processing original vs randomized_sampled_non_roi correlations.\n",
      "     Calculating correlation matrix.\n",
      "     Generating heatmaps for correlations.\n",
      "Plotting vertical feature correlations heatmap...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-01-10T16:44:55-0500\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mFile results/RADCURE/analysis/correlations/cropped_cube/heatmap/nipy_spectral/original_pearson_self_correlation_heatmap.png already exists. Overwriting.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mreadii\u001b[0m]\u001b[0m \u001b[36mcall\u001b[0m=\u001b[35mplot_writer.save:92\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting horizontal feature correlations heatmap...\n",
      "Plotting cross feature correlations heatmap...\n",
      "     Generating histograms for correlations.\n",
      "Plotting vertical feature correlations histogram...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-01-10T16:45:29-0500\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mFile results/RADCURE/analysis/correlations/cropped_cube/histogram/original_pearson_self_correlation_histogram.png already exists. Overwriting.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mreadii\u001b[0m]\u001b[0m \u001b[36mcall\u001b[0m=\u001b[35mplot_writer.save:92\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting horizontal feature correlations histogram...\n",
      "Plotting cross feature correlations histogram...\n"
     ]
    }
   ],
   "source": [
    "# Name of the column used to extract the patient ID for a row of features\n",
    "file_path_column = 'image_path'\n",
    "\n",
    "# Correlation method to apply\n",
    "correlation_method = \"pearson\"\n",
    "\n",
    "# Colormap to use for plots\n",
    "heatmap_cmap = \"nipy_spectral\"\n",
    "\n",
    "# Whether to overwrite existing files\n",
    "overwrite = True\n",
    "\n",
    "# Get and set up the feature dataframe for the original features once\n",
    "vertical_feature_type = \"original\"\n",
    "vertical_features_df = prepPatientIndex(extracted_feature_sets[vertical_feature_type],\n",
    "                                        file_path_column,\n",
    "                                        PAT_ID_PATTERN)\n",
    "\n",
    "# Iterate over each negative control feature set and perform correlation analysis\n",
    "for horizontal_feature_type in negative_control_list:\n",
    "    print(f\"Processing {vertical_feature_type} vs {horizontal_feature_type} correlations.\")\n",
    "\n",
    "    # Generate the output path for matrix file existence check\n",
    "    corr_matrix_output_path = corr_matrix_writer.resolve_path(VerticalFeatureType=vertical_feature_type,\n",
    "                                                              HorizontalFeatureType=horizontal_feature_type,\n",
    "                                                              CorrelationType=correlation_method)\n",
    "    \n",
    "    # Get extracted features for this image type, extract set the patient ID as the dataframe index, remove image_path column\n",
    "    horizontal_features_df = prepPatientIndex(extracted_feature_sets[horizontal_feature_type], \n",
    "                                                file_path_column = file_path_column, \n",
    "                                                pat_id_pattern = PAT_ID_PATTERN)\n",
    "\n",
    "    \n",
    "    # Load existing correlation matrix if it's available\n",
    "    if corr_matrix_output_path.exists() and corr_matrix_output_path.is_file():\n",
    "        print(\"     Loading correlation matrix.\")\n",
    "        feature_correlation_df = pd.read_csv(corr_matrix_output_path, index_col=0)\n",
    "    \n",
    "    # Calculate the correlation matrix if the file doesn't exist\n",
    "    else:\n",
    "        print(\"     Calculating correlation matrix.\")\n",
    "        # Calculate correlations between original image features and image type features\n",
    "        feature_correlation_df = getFeatureCorrelations(vertical_features=vertical_features_df,\n",
    "                                                        horizontal_features=horizontal_features_df,\n",
    "                                                        vertical_feature_name=vertical_feature_type,\n",
    "                                                        horizontal_feature_name=horizontal_feature_type,\n",
    "                                                        method = correlation_method)\n",
    "        # save out the correlation dataframe\n",
    "        corr_matrix_writer.save(feature_correlation_df, \n",
    "                                VerticalFeatureType=vertical_feature_type,\n",
    "                                HorizontalFeatureType=horizontal_feature_type,\n",
    "                                CorrelationType=correlation_method)\n",
    "        \n",
    "    print(\"     Generating heatmaps for correlations.\")\n",
    "    vert_heatmap_path, horiz_heatmap_path, cross_heatmap_path = makeAllHeatmapPlots(feature_correlation_df,\n",
    "                                                                                    vertical_feature_type,\n",
    "                                                                                    horizontal_feature_type,\n",
    "                                                                                    correlations_dir,\n",
    "                                                                                    correlation_method,\n",
    "                                                                                    heatmap_cmap,\n",
    "                                                                                    overwrite)\n",
    "    \n",
    "    print(\"     Generating histograms for correlations.\")\n",
    "    vert_histogram_path, horiz_histogram_path, cross_histogram_path = makeAllHistogramPlots(feature_correlation_df,\n",
    "                                                                                            vertical_feature_type,\n",
    "                                                                                            horizontal_feature_type,\n",
    "                                                                                            correlations_dir,\n",
    "                                                                                            correlation_method,\n",
    "                                                                                            num_bins=450,\n",
    "                                                                                            overwrite=overwrite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readii_fmcib",
   "language": "python",
   "name": "readii_fmcib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
